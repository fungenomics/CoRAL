
#----------------------------------------------------
#  Setup
#----------------------------------------------------

configfile: workflow.basedir + "/Config/config.default.yml"

# import libraries
import os
import sys
import pandas as pd
from datetime import datetime

# import custom functions 
sys.path.insert(0, Path(workflow.basedir).parent.as_posix())
import Scripts.Functions.functions as func

n_folds = list(range(1, config['benchmark']['n_folds']+1)) 

now = datetime.now()
dt_string = now.strftime("%Y-%m-%d_%H-%M-%S")

# set defult parameters
func.set_downsampling_parameters(config)
func.set_ontology_parameters(config)

#print(config )

# get tools to run
tools_to_run = func.get_tools_to_run(config)
consensus_tools = func.get_consensus_tools(config)

#----------------------------------------------------
#  Final rule all 
#----------------------------------------------------

rule all:
  input: 
      expand(config['output_dir_benchmark'] + "/{reference}/report/" + dt_string + '.benchmark_report.html', 
             reference = config['references'].keys())

#----------------------------------------------------
#  Subset Folds 
#----------------------------------------------------

rule subset_folds:   
  input:
    reference = lambda wildcards:config['references'][wildcards.reference]['expression']
  output:
    training_data = expand(config['output_dir_benchmark'] + "/{{reference}}/fold{folds_index}/train.csv", folds_index = n_folds),
    labfile = expand(config['output_dir_benchmark'] + "/{{reference}}/fold{folds_index}/train_labels.csv", folds_index = n_folds),
    test_data = expand(config['output_dir_benchmark'] + "/{{reference}}/fold{folds_index}/test.csv", folds_index = n_folds),
    lab_ontology = config['output_dir_benchmark'] + "/{reference}/ontology/ontology.csv"
  log:
    config['output_dir_benchmark'] + "/{reference}/subset_folds.log"
  params:
    basedir = {workflow.basedir},
    labfile = lambda wildcards:config['references'][wildcards.reference]['labels'],
    outdir = config['output_dir_benchmark'] + "/{reference}",
    reference_name = "{reference}",
    n_folds = config['benchmark']['n_folds'],
    min_cells_per_cluster = lambda wildcards:config["references"][wildcards.reference]['min_cells_per_cluster'],
    downsample_value = lambda wildcards:config["references"][wildcards.reference]['downsample']['value'],
    downsample_stratified = lambda wildcards:config["references"][wildcards.reference]['downsample']['stratified']
  threads: 1
  resources:
  shell:
    """
    Rscript {params.basedir}/Scripts/benchmark/subset_folds.R \
    {input.reference} \
    {params.labfile} \
    {params.outdir} \
    {threads} \
    {params.n_folds} \
    {params.min_cells_per_cluster} \
    {params.downsample_value} \
    {params.downsample_stratified} \
    &> {log}
    """

#----------------------------------------------------
#  Knit Report 
#----------------------------------------------------

rule knit_report:
  input: 
    pred = expand(config['output_dir_benchmark'] + "/{{reference}}/fold{folds_index}/{tool}/{tool}_pred.csv", 
                  folds_index = n_folds, 
                  tool = tools_to_run),
    consensus = expand(config['output_dir_benchmark'] + "/{{reference}}/fold{folds_index}/Prediction_Summary.tsv",
                folds_index = n_folds)
  output: 
    report_path = config['output_dir_benchmark'] + "/{reference}/report/" + dt_string + '.benchmark_report.html'
  log:
    config['output_dir_benchmark'] + "/{reference}/report/report.log"
  params:
    basedir = {workflow.basedir},
    pred_path = config['output_dir_benchmark'] + "/{reference}", 
    n_folds = config['benchmark']['n_folds'],
    tools = tools_to_run,
    min_agree = config['consensus']['type']['majority']['min_agree'],
    ref_name = "{reference}",
    accuracy_metric = "F1"
  resources:
  shell:
    """
    Rscript -e "rmarkdown::render(
            '{params.basedir}/Notebooks/benchmark_report.Rmd',
            params = list(tools = '{params.tools}',
                          ref_name = '{params.ref_name}',
                          pred_path = '{params.pred_path}',
                          min_agree = '{params.min_agree}',
                          fold = '{params.n_folds}',
                          accuracy_metric = '{params.accuracy_metric}'),
            output_file = '{output.report_path}')" \
    &> {log}
    """

#----------------------------------------------------
#  Consensus
#----------------------------------------------------

rule consensus:
  input:
    results = expand(config['output_dir_benchmark'] + "/{{reference}}/fold{{folds_index}}/{tool}/{tool}_pred.csv",
                     tool=tools_to_run)
  output:
    prediction_summary = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/Prediction_Summary.tsv"
  log:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/Gatherpreds.log"
  params:
    basedir = {workflow.basedir},
    tools = tools_to_run,
    consensus_tools = consensus_tools,
    consensus_type = 'majority',
    sample = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}",
    min_agree = config["consensus"]["type"]["majority"]["min_agree"],
    ontology_path = config['output_dir_benchmark'] + "/{reference}/ontology/ontology.csv", 
    ontology_label = "label"
  shell:
    """
    Rscript {params.basedir}/Scripts/calculate_consensus.R \
    {params.sample} \
    {output.prediction_summary} \
    "{params.tools}" \
    "{params.consensus_tools}" \
    "{params.consensus_type}" \
    "{params.min_agree}" \
    "{params.ontology_label}" \
    "{params.ontology_path}" \
    &> {log}
    """

#----------------------------------------------------
#   scPred 
#----------------------------------------------------

rule train_scPred:
  input:
    reference = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/train.csv",
    labfile = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/train_labels.csv"
  output:
    model = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/scPred_{classifier}/scPred_{classifier}.Rda"
  params:
    basedir = {workflow.basedir},
    classifier = "{classifier}"
  log:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/scPred_{classifier}/scPred_{classifier}.log"
  benchmark:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/scPred_{classifier}/scPred_{classifier}_train_benchmark.txt"
  threads: 
    config['scPred']['threads']
  resources:
  shell:
    """
    Rscript {params.basedir}/Scripts/scPred/train_scPred.R \
    {input.reference} \
    {input.labfile} \
    {output.model} \
    {threads} \
    {params.classifier} \
    &> {log}
    """

rule predict_scPred:
  input:
    query = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/test.csv",
    model = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/scPred_{classifier}/scPred_{classifier}.Rda" 
  output:
    pred = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/scPred_{classifier}/scPred_{classifier}_pred.csv" 
  params:
    basedir = {workflow.basedir},
    classifier = "{classifier}"
  log:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/scPred_{classifier}/scPred_{classifier}.log"
  benchmark:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/scPred_{classifier}/scPred_{classifier}_predict_benchmark.txt"
  threads: 
    config['scPred']['threads']
  resources:
  shell:
    """
    Rscript {params.basedir}/Scripts/scPred/predict_scPred.R \
    {input.query} \
    {input.model} \
    {output.pred} \
    {threads} \
    {params.classifier} \
    &> {log}
    """

rule gather_scPred:
  input:
    expand(config['output_dir_benchmark'] + "/{{reference}}/fold{{folds_index}}/scPred_{classifier}/scPred_{classifier}_pred.csv",
    classifier = config['scPred']['classifier'])
    
#----------------------------------------------------
#   SingleR 
#----------------------------------------------------

rule train_SingleR:
  input:
    reference = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/train.csv",
    labfile = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/train_labels.csv"
  output:
    model = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/SingleR/SingleR_model.Rda"
  params:
    basedir = {workflow.basedir},
  log:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/SingleR/SingleR.log"
  benchmark:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/SingleR/SingleR_train_benchmark.txt"
  threads: 
    config['SingleR']['threads']
  resources:
  shell:
    """
    Rscript {params.basedir}/Scripts/SingleR/train_SingleR.R \
    {input.reference} \
    {input.labfile} \
    {output.model} \
    {threads} \
    &> {log}
    """

rule predict_SingleR:
  input:
    query = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/test.csv",
    model = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/SingleR/SingleR_model.Rda" 
  output:
    pred = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/SingleR/SingleR_pred.csv" 
  params:
    basedir = {workflow.basedir}
  log:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/SingleR/SingleR.log"
  benchmark:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/SingleR/SingleR_predict_benchmark.txt"
  threads: 
    config['SingleR']['threads']
  resources:
  shell:
    """
    Rscript {params.basedir}/Scripts/SingleR/predict_SingleR.R \
    {input.query} \
    {input.model} \
    {output.pred} \
    {threads} \
    &> {log}
    """

#----------------------------------------------------
#   scClassify
#----------------------------------------------------

rule train_scClassify:
  input:
    reference = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/train.csv",
    labfile = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/train_labels.csv"
  output:
    model = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/scClassify/scClassify_model.Rda"
  params:
    basedir = {workflow.basedir},
    topN = config['scClassify']['topN'], 
    weightsCal = config['scClassify']['weightsCal'],
    hopach_kmax = config['scClassify']['hopach_kmax']
  log:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/scClassify/scClassify.log"
  benchmark:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/scClassify/scClassify_train_benchmark.txt"
  threads: 
    config['scClassify']['threads']
  resources:
  shell:
    """
    Rscript {params.basedir}/Scripts/scClassify/train_scClassify.R \
    {input.reference} \
    {input.labfile} \
    {output.model} \
    {threads} \
    {params.topN} \
    {params.weightsCal} \
    {params.hopach_kmax} \
    &> {log}
    """

rule predict_scClassify:
  input:
    query = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/test.csv",
    model = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/scClassify/scClassify_model.Rda" 
  output:
    pred = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/scClassify/scClassify_pred.csv"
  params:
    basedir = {workflow.basedir}, 
    algorithm = config['scClassify']['algorithm'],
    similarity = config['scClassify']['similarity'],
    prob_threshold = config['scClassify']['prob_threshold'],
    cor_threshold_static = config['scClassify']['cor_threshold_static'],
    cor_threshold_high = config['scClassify']['cor_threshold_high']
  log:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/scClassify/scClassify.log"
  benchmark:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/scClassify/scClassify_predict_benchmark.txt"
  threads: 
    config['scClassify']['threads']
  resources:
  shell:
    """
    Rscript {params.basedir}/Scripts/scClassify/predict_scClassify.R \
    {input.query} \
    {input.model} \
    {output.pred} \
    {threads} \
    {params.algorithm} \
    {params.similarity} \
    {params.prob_threshold} \
    {params.cor_threshold_static} \
    {params.cor_threshold_high} \
    &> {log}
    """

#----------------------------------------------------
#   SciBet
#----------------------------------------------------

rule train_SciBet:
  input:
    reference = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/train.csv",
    labfile = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/train_labels.csv"
  output:
    model = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/SciBet/SciBet_model.Rda"
  params:
    basedir = {workflow.basedir},
  log:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/SciBet/SciBet.log"
  benchmark:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/SciBet/SciBet_train_benchmark.txt"
  threads: 
    config['SciBet']['threads']
  resources:
  shell:
    """
    Rscript {params.basedir}/Scripts/SciBet/train_SciBet.R \
    {input.reference} \
    {input.labfile} \
    {output.model} \
    {threads} \
    &> {log}
    """

rule predict_SciBet:
  input:
    query = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/test.csv",
    model = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/SciBet/SciBet_model.Rda" 
  output:
    pred = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/SciBet/SciBet_pred.csv"
  params:
      basedir = {workflow.basedir}
  log:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/SciBet/SciBet.log"
  benchmark:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/SciBet/SciBet_predict_benchmark.txt"
  threads: 
    config['SciBet']['threads']
  resources:
  shell:
    """
    Rscript {params.basedir}/Scripts/SciBet/predict_SciBet.R \
    {input.query} \
    {input.model} \
    {output.pred} \
    {threads} \
    &> {log}
    """

#----------------------------------------------------
#   SVM Linear
#----------------------------------------------------

rule train_SVMlinear:
  input:
    reference = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/train.csv",
    labfile = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/train_labels.csv"
  output:
    model = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/SVMlinear/SVMlinear_model.Rda"
  params:
    basedir = {workflow.basedir}
  log:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/SVMlinear/SVMlinear.log"
  benchmark:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/SVMlinear/SVMlinear_train_benchmark.txt"
  threads: 
    config['SVMlinear']['threads']
  resources:
  shell:
    """
    python {params.basedir}/Scripts/SVC/train_linearSVM.py \
    {input.reference} \
    {input.labfile} \
    {output.model} \
    {threads} \
    &> {log}
    """

rule predict_SVMlinear:
  input:
    query = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/test.csv",
    model = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/SVMlinear/SVMlinear_model.Rda"
  output:
    pred = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/SVMlinear/SVMlinear_pred.csv"
  params:
    basedir = {workflow.basedir},
    threshold = config['SVMlinear']['threshold'],
    tool_name = config['SVMlinear']['classifier']
  log:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/SVMlinear/SVMlinear.log"
  benchmark:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/SVMlinear/SVMlinear_predict_benchmark.txt"
  threads:  
    config['SVMlinear']['threads']
  resources:
  shell:
    """
    python {params.basedir}/Scripts/SVC/predict_SVM.py \
    {input.query} \
    {input.model} \
    {output.pred} \
    {params.threshold} \
    {threads} \
    {params.tool_name} \
    &> {log}
    """

#----------------------------------------------------
#   SVC 
#----------------------------------------------------

rule train_SVC:
  input:
    reference = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/train.csv",
    labfile = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/train_labels.csv"
  output:
    model = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/SVC/SVC_model.pkl"
  params:
    basedir = {workflow.basedir}
  log:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/SVC/SVC.log"
  benchmark:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/SVC/SVC_train_benchmark.txt"
  threads: 
    config['SVC']['threads']
  resources:
  shell:
    """
    python {params.basedir}/Scripts/SVC/train_SVM.py \
    {input.reference} \
    {input.labfile} \
    {output.model} \
    {params.classifier} \
    {threads} \
    &> {log}
    """

rule predict_SVC:
  input:
    query = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/test.csv",
    model = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/SVC/SVC_model.pkl"
  output:
    pred = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/SVC/SVC_pred.csv"
  params:
    basedir = {workflow.basedir},
    threshold = config['SVC']['threshold'],
    tool_name = config['SVC']['classifier']
  log:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/SVC/SVC.log"
  benchmark:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/SVC/SVC_predict_benchmark.txt"
  threads: 
    config['SVC']['threads']
  resources:
  shell:
    """
    python {params.basedir}/Scripts/SVC/predict_SVM.py \
    {input.query} \
    {input.model} \
    {output.pred} \
    {params.threshold} \
    {threads} \
    {params.tool_name} \
    &> {log}
    """

#----------------------------------------------------
#   singleCellNet
#----------------------------------------------------

rule train_singleCellNet:
  input:
    reference = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/train.csv",
    labfile = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/train_labels.csv"
  output:
    model = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/singleCellNet/singleCellNet_model.Rda"
  params:
    basedir = {workflow.basedir},
    nTrees = config['singleCellNet']['nTrees']
  log:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/singleCellNet/singleCellNet.log"
  benchmark:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/singleCellNet/singleCellNet_train_benchmark.txt"
  threads: 
    config['singleCellNet']['threads']
  resources:
  shell:
    """
    Rscript {params.basedir}/Scripts/singleCellNet/train_singleCellNet.R \
    {input.reference} \
    {input.labfile} \
    {output.model} \
    {threads} \
    {params.nTrees} \
    &> {log}
    """

rule predict_singleCellNet:
  input:
    query = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/test.csv",
    model = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/singleCellNet/singleCellNet_model.Rda" 
  output:
    pred = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/singleCellNet/singleCellNet_pred.csv"
  params:
      basedir = {workflow.basedir}
  log:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/singleCellNet/singleCellNet.log"
  benchmark:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/singleCellNet/singleCellNet_predict_benchmark.txt"
  threads: 
    config['singleCellNet']['threads']
  resources:
  shell:
    """
    Rscript {params.basedir}/Scripts/singleCellNet/predict_singleCellNet.R \
    {input.query} \
    {input.model} \
    {output.pred} \
    {threads} \
    &> {log}
    """

#----------------------------------------------------
#   Correlation 
#----------------------------------------------------

rule train_Correlation:
  input:
    reference = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/train.csv",
    labfile = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/train_labels.csv"
  output:
    model = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/Correlation/Correlation_model.Rda"
  params:
    basedir = {workflow.basedir},
  log:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/Correlation/Correlation.log"
  benchmark:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/Correlation/Correlation_train_benchmark.txt"
  threads: 
    config['Correlation']['threads']
  resources:
  shell:
    """
    Rscript {params.basedir}/Scripts/Correlation/train_Correlation.R \
    {input.reference} \
    {input.labfile} \
    {output.model} \
    {threads} \
    &> {log}
    """
rule predict_Correlation:
  input:
    query = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/test.csv",
    model = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/Correlation/Correlation_model.Rda"
  output:
    pred = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/Correlation/Correlation_pred.csv"
  params:
      basedir = {workflow.basedir}
  log:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/Correlation/Correlation.log"
  benchmark:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/Correlation/Correlation_predict_benchmark.txt"
  threads: 
    config['Correlation']['threads']
  resources:
  shell:
    """
    Rscript {params.basedir}/Scripts/Correlation/predict_Correlation.R \
    {input.query} \
    {input.model} \
    {output.pred} \
    {threads} \
    &> {log}
    """

#----------------------------------------------------
#   scLearn 
#----------------------------------------------------

rule train_scLearn: 
  input:
    reference = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/train.csv",
    labfile = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/train_labels.csv"
  output:
    model = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/scLearn/scLearn_model.Rda"
  params:
    basedir = {workflow.basedir},
    bootstrap_times = config['scLearn']['bootstrap_times']
  log:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/scLearn/scLearn.log"
  benchmark:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/scLearn/scLearn_train_benchmark.txt"
  threads: 
    config['scLearn']['threads']
  resources:
  shell:
    """
    Rscript {params.basedir}/Scripts/scLearn/train_scLearn.R \
    {input.reference} \
    {input.labfile} \
    {output.model} \
    {threads} \
    {params.bootstrap_times} \
    &> {log}
    """

rule predict_scLearn:
  input:
    query = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/test.csv",
    model = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/scLearn/scLearn_model.Rda"
  output:
    pred = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/scLearn/scLearn_pred.csv"
  params:
      basedir = {workflow.basedir}
  log:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/scLearn/scLearn.log"
  benchmark:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/scLearn/scLearn_predict_benchmark.txt"
  threads: 
    config['scLearn']['threads']
  resources:
  shell:
    """
    Rscript {params.basedir}/Scripts/scLearn/predict_scLearn.R \
    {input.query} \
    {input.model} \
    {output.pred} \
    {threads} \
    &> {log}
    """

#----------------------------------------------------
#   scHPL
#----------------------------------------------------

rule train_scHPL:
  input:
    reference = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/train.csv",
    labfile = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/train_labels.csv"
  output:
    model = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/scHPL/scHPL_model.Rda"
  params:
    basedir = {workflow.basedir},
    classifier = config['scHPL']['classifier'],
    dimred = config['scHPL']['dimred']
  log:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/scHPL/scHPL.log"
  benchmark:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/scHPL/scHPL_train_benchmark.txt"
  threads: 
    config['scHPL']['threads']
  resources:
  shell:
    """
    python {params.basedir}/Scripts/scHPL/train_scHPL.py \
    {input.reference} \
    {input.labfile} \
    {output.model} \
    {params.classifier} \
    {params.dimred} \
    &> {log}
    """

rule predict_scHPL:
  input:
    query = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/test.csv",
    model = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/scHPL/scHPL_model.Rda"
  output:
    pred = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/scHPL/scHPL_pred.csv"
  params:
    basedir = {workflow.basedir},
    threshold = config['scHPL']['threshold']
  log:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/scHPL/scHPL.log"
  benchmark:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/scHPL/scHPL_predict_benchmark.txt"
  threads: 
    config['scHPL']['threads']
  resources:
  shell:
    """
    python {params.basedir}/Scripts/scHPL/predict_scHPL.py \
    {input.query} \
    {input.model} \
    {output.pred} \
    {params.threshold} \
    &> {log}
    """

#----------------------------------------------------
#   ACTINN
#----------------------------------------------------

rule train_ACTINN:
  input:
    reference = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/train.csv",
    labfile = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/train_labels.csv"
  output:
    model = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/ACTINN/ACTINN_model.pkl"
  params:
    basedir = {workflow.basedir}
  log:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/ACTINN/ACTINN.log"
  benchmark:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/ACTINN/ACTINN_predict_benchmark.txt"
  threads: 
    config['ACTINN']['threads']
  shell:
    """
    python {params.basedir}/Scripts/ACTINN/train_ACTINN.py \
           -trs {input.reference} \
           -trl {input.labfile} \
                 -mp {output.model} \
    &> {log}
    """

rule predict_ACTINN:
  input:
    query = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/test.csv",
    model = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/ACTINN/ACTINN_model.pkl"
  output:
    pred = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/ACTINN/ACTINN_pred.csv"
  params:
    basedir = {workflow.basedir}
  log:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/ACTINN/ACTINN.log"
  benchmark:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/ACTINN/ACTINN_predict_benchmark.txt"
  threads: 
    config['ACTINN']['threads']
  resources:
  shell:
    """
    python {params.basedir}/Scripts/ACTINN/predict_ACTINN.py \
           -ts {input.query} \
           -mp {input.model} \
           -pp {output.pred} \
    &> {log}

    """

#----------------------------------------------------
#   scID
#----------------------------------------------------

rule run_scID:
  input:
    reference = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/train.csv",
    labfile = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/train_labels.csv",
    query = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/test.csv"
  output:
    pred = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/scID/scID_pred.csv"
  params:
    basedir = {workflow.basedir},
    estimate_weights_from_target = config['scID']['estimate_weights_from_target'],
    logFC = config['scID']['logFC']
  log:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/scID/scID.log"
  benchmark:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/scID/scID_benchmark.txt"
  threads: 
    config['scID']['threads']
  shell:
    """
    Rscript {params.basedir}/Scripts/scID/run_scID.R \
            {input.reference} \
            {input.labfile} \
            {input.query} \
            {output.pred} \
            {threads} \
            {params.estimate_weights_from_target} \
            {params.logFC} \
    &> {log}
    """

#----------------------------------------------------
#   scAnnotate
#----------------------------------------------------

rule run_scAnnotate:
  input:
    reference = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/train.csv",
    labfile = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/train_labels.csv",
    query = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/test.csv"
  output:
    pred = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/scAnnotate/scAnnotate_pred.csv"
  params:
    basedir = {workflow.basedir},
    threshold = 0.5
  log:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/scAnnotate/scAnnotate.log"
  benchmark:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/scAnnotate/scAnnotate_benchmark.txt"
  threads: 
    config['scAnnotate']['threads']
  shell:
    """
    Rscript {params.basedir}/Scripts/scAnnotate/run_scAnnotate.R \
            {input.reference} \
            {input.labfile} \
            {input.query} \
            {output.pred} \
            {threads} \
            {params.threshold} \
    &> {log}
    """

#----------------------------------------------------
#   scNym
#----------------------------------------------------

rule run_scNym:
  input:
    reference = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/train.csv",
    labfile = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/train_labels.csv",
    query = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/test.csv"
  output:
    pred = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/scNym/scNym_pred.csv"
  params:
    basedir = {workflow.basedir},
    threshold = 0.5
  log:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/scNym/scNym.log"
  benchmark:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/scNym/scNym_benchmark.txt"
  threads: 
    config['scNym']['threads']
  shell:
    """
    python {params.basedir}/Scripts/scNym/run_scNym.py \
            {input.reference} \
            {input.labfile} \
            {input.query} \
            {output.pred} \
            {params.threshold} \
    &> {log}
    """

#----------------------------------------------------
#   CellTypist
#----------------------------------------------------

rule train_CellTypist:
  input:
    reference = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/train.csv",
    labfile = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/train_labels.csv"
  output:
    model = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/CellTypist/CellTypist_model.pkl"
  params:
    basedir = {workflow.basedir},
    feature_selection = config['CellTypist']['feature_selection']
  log:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/CellTypist/CellTypist.log"
  benchmark:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/CellTypist/CellTypist_train_benchmark.txt"
  threads: 
    config['CellTypist']['threads']
  resources:
  shell:
    """
    python {params.basedir}/Scripts/CellTypist/train_CellTypist.py \
    {input.reference} \
    {input.labfile} \
    {output.model} \
    {threads} \
    {params.feature_selection} \
    &> {log}
    """

rule predict_CellTypist:
  input:
    query = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/test.csv",
    model = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/CellTypist/CellTypist_model.pkl"
  output:
    pred = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/CellTypist/CellTypist_pred.csv"
  params:
    basedir = {workflow.basedir},
    threshold = config['CellTypist']['threshold'],
    majority_voting = config['CellTypist']['majority_voting']
  log:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/CellTypist/CellTypist.log"
  benchmark:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/CellTypist/CellTypist_predict_benchmark.txt"
  threads: 
    config['CellTypist']['threads']
  resources:
  shell:
    """
    python {params.basedir}/Scripts/CellTypist/predict_CellTypist.py \
    {input.query} \
    {input.model} \
    {output.pred} \
    {params.threshold} \
    {threads} \
    {params.majority_voting} \
    &> {log}
    """
    
#----------------------------------------------------
#   Seurat 
#----------------------------------------------------

rule train_Seurat:
  input:
    reference = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/train.csv",
    labfile = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/train_labels.csv"
  output:
    model = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/Seurat/Seurat_model.Rda"
  params:
    basedir = {workflow.basedir},
    nPC_computed = config['Seurat']['nPC_computed']
  log:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/Seurat/Seurat.log"
  benchmark:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/Seurat/Seurat_train_benchmark.txt"
  threads: 
    config['Seurat']['threads']
  resources:
  shell:
    """
    Rscript {params.basedir}/Scripts/Seurat/train_Seurat.R \
    {input.reference} \
    {input.labfile} \
    {output.model} \
    {threads} \
    {params.nPC_computed} \
    &> {log}
    """
rule predict_Seurat:
  input:
    query = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/test.csv",
    model = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/Seurat/Seurat_model.Rda"
  output:
    pred = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/Seurat/Seurat_pred.csv"
  params:
    basedir = {workflow.basedir},
    nPC_used = config['Seurat']['nPC_used']
  log:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/Seurat/Seurat.log"
  benchmark:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/Seurat/Seurat_predict_benchmark.txt"
  threads: 
    config['Seurat']['threads']
  resources:
  shell:
    """
    Rscript {params.basedir}/Scripts/Seurat/predict_Seurat.R \
    {input.query} \
    {input.model} \
    {output.pred} \
    {threads} \
    {params.nPC_used} \
    &> {log}
    """

#----------------------------------------------------
#   scPoli
#----------------------------------------------------

rule train_scPoli:
  input:
    reference = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/train.csv",
    labfile = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/train_labels.csv"
  output:
    model = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/scPoli/scPoli_model.pkl"
  params:
    basedir = {workflow.basedir}
  log:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/scPoli/scPoli.log"
  benchmark:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/scPoli/scPoli_train_benchmark.txt"
  shell:
    """
    python {params.basedir}/Scripts/scPoli/train_scPoli.py \
    {input.reference} \
    {input.labfile} \
    {output.model} \
    &> {log}
    """

rule predict_scPoli:
  input:
    query = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/test.csv",
    model = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/scPoli/scPoli_model.pkl"
  output:
    pred = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/scPoli/scPoli_pred.csv"
  params:
    basedir = {workflow.basedir}
  log:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/scPoli/scPoli.log"
  benchmark:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/scPoli/scPoli_predict_benchmark.txt"
  shell:
    """
    python {params.basedir}/Scripts/scPoli/predict_scPoli.py \
    {input.query} \
    {input.model} \
    {output.pred} \
    &> {log}
    """

#----------------------------------------------------
#   scANVI
#----------------------------------------------------

rule train_scANVI:
  input:
    reference = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/train.csv",
    labfile = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/train_labels.csv"
  output:
    model = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/scANVI/model.pt"
  params:
    basedir = {workflow.basedir}
  log:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/scANVI/scANVI.log"
  benchmark:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/scANVI/scANVI_train_benchmark.txt"
  shell:
    """
    python {params.basedir}/Scripts/scANVI/train_scANVI.py \
    {input.reference} \
    {input.labfile} \
    {output.model} \
    &> {log}
    """

rule predict_scANVI:
  input:
    query = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/test.csv",
    model = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/scANVI/model.pt"
  output:
    pred = config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/scANVI/scANVI_pred.csv"
  params:
    basedir = {workflow.basedir},
    threshold = config['scANVI']['threshold']
  log:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/scANVI/scANVI.log"
  benchmark:
    config['output_dir_benchmark'] + "/{reference}/fold{folds_index}/scANVI/scANVI_predict_benchmark.txt"
  shell:
    """
    python {params.basedir}/Scripts/scANVI/predict_scANVI.py \
    {input.query} \
    {input.model} \
    {output.pred} \
    {params.threshold} \
    &> {log}
    """

#----------------------------------------------------
#   The End 
#----------------------------------------------------
